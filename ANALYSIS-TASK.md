### Анализ задачи

- a. Что было сделано 
  - Реализован сбор данных по средствам ООП
  - Изолирование функциональности парсера, что позволяет с легкостью расширять функционал
  - Создание модели данных для лучше читаемости
  - Добавление логирование на уровни debug для понимания процесса выполнения, так же обработка запросов `requests`
  - Сохранение результатов в `json` файл

  
- b. Откуда были получены данные 
  - Данные были получены с сайта `quotes.toscrape.com`


- c. Как осуществлялся сбор 
  - Первоначально ресурс был изучен через инспектор страницы 
  - Сбор выполнялся при использовании `BeautifulSoup4` и `requests`
  - Получение содержимого страницы выполнялся через `reqeusts`
  - Парсинг блоков, тегов и атрибутов через `BeautifulSoup4`


- d. Почему был выбран тот или иной метод/инструмент, а не другой
  - Были выбраны `BeautifulSoup4` и `requests` по причине того что ресурс возвращает с сервера полностью сформированный HTML-страницы
  - Т.к. для парсинга таких страниц достаточно обычных запросов, то реализация задачи не нуждалась в имитации браузера или обхода защит от ботов
  - Если бы ресурс использовал API для получения цитат, то можно было бы избежать парсинг с помощью `BeautifulSoup4`
  - Если бы ресурс подгружал данные динамически в `DOM-дерево` или использовал защиту от ботов, то пришлось бы использовать имитацию браузера 
